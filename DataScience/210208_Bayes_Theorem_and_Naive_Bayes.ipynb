{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210208 Bayes Theorem and Naive Bayes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3T8ZV4rg2RtMhsW20X/wY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongwonTak/TIL_swtak/blob/master/DataScience/210208_Bayes_Theorem_and_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2EamXjwxLSE"
      },
      "source": [
        "#210208 Bayes Theorem and Naive Bayes\r\n",
        "\r\n",
        "분류 모델 중 하나인 나이브 베이즈에 대해 알아보려고 한다.\r\n",
        "이를 위해서는 먼저 베이즈 정리에 대해 자세히 알아야 한다.\r\n",
        "\r\n",
        "베이즈 정리가 무엇인지 알아보고  나이브 베이즈가 무엇인지 알아보자. 왜 그런것을 생각할 수 있는지 생각해보자.\r\n",
        "\r\n",
        "참고자료 : \r\n",
        "- 밑바닥부터 시작하는 데이터 과학\r\n",
        "- 데이터 사이언스 스쿨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I564j1xdx8Sv"
      },
      "source": [
        "## 1. 두 사건에 대한 베이즈 정리\r\n",
        "\r\n",
        "(조건부 확률에 대한 설명은 생략한다)\r\n",
        "먼저 사전확률과 사후확률에 대한 개념을 다시 정리하려고 한다.\r\n",
        "\r\n",
        "두 사건에 대한 상황부터 먼저 생각할려고 한다.\r\n",
        "두 사건 $A, B$가 주어질 때,\r\n",
        "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\r\n",
        "\r\n",
        "이를 베이즈 정리라고 한다.\r\n",
        "증명 자체는 조건부 확률의 정의에 의해 쉽게 얻을 수 있다.\r\n",
        "하지만 이 식의 의미에 대해 정리 하려고 한다.\r\n",
        "\r\n",
        "- $P(A)$ : Prior, 사전확률. \r\n",
        "- $P(A|B)$ : Posterior, 사후 확률. 사건 B가 일어난 후 갱신된 사건 A의 확률 \r\n",
        "- $P(B|A)$ : Likelihood, 가능도\r\n",
        "- $P(B)$ : 정규화 상수.\r\n",
        "\r\n",
        "$P(B)$가 일어남을 알면서 사건 $A$의 확률 변화를 관찰하는 것이 목표."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwyB2HSU67mn"
      },
      "source": [
        "## 2. 여러 사건에 대한 베이즈 정리\r\n",
        "\r\n",
        "만약 사건 $A_{i}$들이 다음을 만족시킨다면.\r\n",
        "- 서로 배타적이다.\r\n",
        "$$ A_{i} \\cap A_{j} = \\emptyset$$\r\n",
        "- 합집합은 표본공간 전체\r\n",
        "$$ \\cup_{i=1}^{n}A_{i} = \\Omega$$\r\n",
        "\r\n",
        "베이즈 정리는 다음과 같이 확장된다.\r\n",
        "\r\n",
        "$$ P(A_{1}|B) = \\frac{P(B|A_{1})P(A_{1})}{\\sum_{i}P(B|A_{i})P(A_{i})}$$\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuX0HrVE8lwR"
      },
      "source": [
        "예시를 통해 이에 대해 정리하려고 한다.\r\n",
        "\r\n",
        "특정 병을 검사하는 약이 있다. 그 병에 걸린 사람에게 이 약을 테스트 한 결과 95% 확률로 양성 반응을 보였다.\r\n",
        "병에 걸린지 모르는 환자에게 이 약을 테스트했다. 양성반응을 보였다면, 실제로 그 병에 걸릴 확률은?\r\n",
        "\r\n",
        "단, 이 병은 전체 인구중 0.5%가 걸린 질병이며, 이 병에 걸리지 않은 사람에게 이 약을 검사한 결과 양성 반응을 나타낸 확률은 2% 이다.\r\n",
        "\r\n",
        "\r\n",
        "이 문제를 위의 정리를 통해 해결하자.\r\n",
        "사건 $A$ : 질병에 걸렸다.\r\n",
        "사건 $B$ : 양성 반응을 보였다.\r\n",
        "\r\n",
        "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|A^{C})P(A^{C})} $$\r\n",
        "\r\n",
        "이 값을 계산하면, \r\n",
        "$$ \\frac{0.95*0.005}{0.95*0.005+0.2*0.995}=0.0233...$$\r\n",
        "\r\n",
        "이럴수가! 실제 계산 결과 그 병에 걸릴 확률은 매우 낮다!\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUOy8USy-ZnF"
      },
      "source": [
        "## 3. 나이브 베이즈란?\r\n",
        "\r\n",
        "베이즈 정리를 기반으로 한 모델인 나이브 베이즈는 분류 모델에서 스팸 필터, 텍스트 분류 등 다양한 범위에서 활용 가능한 기법이다.\r\n",
        "\r\n",
        "나이브 베이즈에서는 분류, 즉 Label 값을 찾기 위한 **Feature들이 서로 독립이라는 가정이 필요**하다.\r\n",
        "\r\n",
        "스팸 필터 문제를 상정해보자.\r\n",
        "단어, $w_{1}, w_{2}, ... , w_{n}$이 주어졌다고 한다. w_{i}가 메세지에 포함되는 경우를 X_{i}로 나타내자. \r\n",
        "그럼 스팸메일이다 라는 사건을 $S$ 라고 하자.\r\n",
        "\r\n",
        "풀고 싶은 문제는, **특정 단어가 들어가면 정말 스팸메일일까?**\r\n",
        "$P(S|X_{i})$를 구하는 문제이므로 이를 베이즈 정리에 의해 계산한다.\r\n",
        "\r\n",
        "$$P(S|X_{i}) = \\frac{P(X_{i}|S)P(S)}{P(X_{i}|S)P(S)+{P(X_{i}|S^{C})P(S^{C})}}$$\r\n",
        "\r\n",
        "나이브 베이즈의 **'독립'** 가정을 다시 떠올리자. 이젠 각 단어가 메세지에 포함될 확률값을 곱할 수가 있다.!\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkYPIB5IGD6W"
      },
      "source": [
        "하지만 이를 이대로 쓴다면 문제가 발생할 것이다.\r\n",
        "예를 들어, **데이터의 불균형이 발생하여** 특정 단어는 스팸이 아닌 메시지에만 포함이 되어있다고 가정하자.\r\n",
        "즉, $P(x_{i}|S) = 0 $이라는 의미이다. 이 경우 나이브 베이즈는 그 단어가 들어가는 모든 메일은 스팸이 아니라고 예측할 것이다. 이게 정상일까?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTPpRNxgGX1K"
      },
      "source": [
        "## 4. 라플라스 스무딩(Laplace Smoothing)\r\n",
        "이를 위해 가짜 빈도수(pseudocount)를 더하게 된다.\r\n",
        "이렇게 될 경우 한쪽으로 몰린 불균형이 해소된다.\r\n",
        "\r\n",
        "$P(X_{i}|S)$는 이제 $w_i$를 포함하는 스팸 메일수에 k를 더한 값을 전체 스팸 메일 수에 2k를 더한 값을 나누게 된다. 이제 이 k를 조정하여 스무딩의 정도를 조정할 수 있게 된다."
      ]
    }
  ]
}