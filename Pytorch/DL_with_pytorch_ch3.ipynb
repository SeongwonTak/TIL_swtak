{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_with_pytorch_ch3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNshe3fD1ouVlcgUBwrMHOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongwonTak/TIL_swtak/blob/master/Pytorch/DL_with_pytorch_ch3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDJojH38qkN5"
      },
      "source": [
        "# Pytorch로 시작하는 딥러닝 3장\n",
        "\n",
        "추천 시스템 개발 연습에 미뤄두었던 Pytorch로 시작하는 딥러닝을 다시 읽기 시작했다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfW_EFjTqsJq"
      },
      "source": [
        "## 신경망의 구성 요소\n",
        "딥러닝 알고리즘 학습을 위해서는 다음것들이 필요하다.\n",
        "- Data Pipeline의 구축\n",
        "- 신경망 아키텍처의 구축\n",
        "- 오차함수를 이용한 아키텍처의 평가\n",
        "- 최적화 알고리즘을 통한 가중치 최적화\n",
        "\n",
        "여기서, 데이터를 입력받고 변환, 데이터 출력 등의 진행이 일어나는 것이 Layer이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_p_0_KCtS9R"
      },
      "source": [
        "### Linear Layer\n",
        "입력 데이터에 선형 변환을 실시한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgqfF59Rqent"
      },
      "source": [
        "from torch.nn import Linear\n",
        "myLayer = Linear(in_features=10, out_features=5, bias=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9tWZ-Oqtm2H",
        "outputId": "3f056ce3-0164-44e7-c7d2-833b8972689a"
      },
      "source": [
        "import torch\n",
        "inputs = torch.randn(10)\n",
        "myLayer(inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3043,  0.3279, -0.5284,  0.1655,  0.1435], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRAnYXXZuLz_"
      },
      "source": [
        "여기서 weight과 bias를 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a1i2mVOuOcP",
        "outputId": "dccb09e5-8206-48c7-e095-9c018ec60ace"
      },
      "source": [
        "myLayer.weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0607, -0.0157, -0.1399, -0.2390,  0.3099,  0.1081,  0.3100,  0.0038,\n",
              "          0.1653, -0.1457],\n",
              "        [-0.0105, -0.1517,  0.1091, -0.3012,  0.0748,  0.1228,  0.2021, -0.3095,\n",
              "          0.1208,  0.0443],\n",
              "        [-0.0350, -0.3157, -0.0953,  0.0062,  0.0467, -0.2658, -0.1403, -0.0814,\n",
              "         -0.2917, -0.0564],\n",
              "        [-0.1532, -0.1766, -0.0888, -0.1542,  0.1929,  0.2613, -0.2622,  0.0666,\n",
              "         -0.0416,  0.0662],\n",
              "        [ 0.1608,  0.2548, -0.1372, -0.2340,  0.1273,  0.2292, -0.2390, -0.0089,\n",
              "          0.1897, -0.1561]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JHePnjquRHn",
        "outputId": "ec5963c2-121b-419a-a9d7-dbb960ccf76f"
      },
      "source": [
        "myLayer.bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.0602, -0.1389, -0.1575,  0.1735, -0.1273], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfiEmKtguV5B"
      },
      "source": [
        "복수 레이어 또한 구현이 가능하며, 이의 경우는 다음 레이어에 이전 레이어의 출력을 입력하면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYpj6tg9uaEH",
        "outputId": "a9de08dd-2979-493b-e544-4d0061eef6ea"
      },
      "source": [
        "#복수 레이어의 예시\n",
        "myLayer1 = Linear(10, 5)\n",
        "myLayer2 = Linear(5, 2)\n",
        "myLayer2(myLayer1(inputs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0125,  0.5872], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeTizY4GumJX"
      },
      "source": [
        "### 활성화 함수\n",
        "물론, 당연히 이미 밑딥애서 배웠지만, 선형함수로만 층을 쌓는것은 의미가 없다.\n",
        "Pytorch에서 활성화 함수의 구현은 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1x2H5CZuldP",
        "outputId": "5f503d32-06bb-484c-ecda-655288e57ecc"
      },
      "source": [
        "# ReLU와 Sigmoid의 사용법\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sigmoid\n",
        "\n",
        "sample_data = torch.Tensor([[1, 2, -1, -0.5, 3]])\n",
        "relu = ReLU()  # 이렇게 함수를 한 번 정의하고 넘어가야 한다...\n",
        "sigmoid = Sigmoid()  # 이것도.\n",
        "print(relu(sample_data))\n",
        "print(sigmoid(sample_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 0., 0., 3.]])\n",
            "tensor([[0.7311, 0.8808, 0.2689, 0.3775, 0.9526]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj8j17Sevvwv"
      },
      "source": [
        "## 딥러닝 알고리즘의 구현\n",
        "(어찌보면 당연한거지만) 신경망은 class 형태로 개발된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g7MmSHN_LHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "17faf410-23d9-450b-d7ef-55900b3cd90f"
      },
      "source": [
        "\n",
        "class MyFirstNewtork(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(MyFirstNewtork, self).__init__()\n",
        "    self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "    self.layer2 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    out = self.layer1(input)\n",
        "    out = nn.ReLU(out)\n",
        "    out = self.layer2(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3cc7ec26a9ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMyFirstNewtork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyFirstNewtork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eywU3aXvLvch"
      },
      "source": [
        "### 마지막 레이어의 결정\n",
        "해결하려는 문제의 유형에 따라, 마지막 레이어의 형태가 결정된다.\n",
        "- 회귀 : 선형 레이어의 적용하여 연속적인 값 1개 출력\n",
        "- 이진분류 : 시그모이드를 활용하여 0 또는 1에 가까운 값 출력\n",
        "- 다중분류 : 소프트맥스 함수를 활용하여, 개별 확률을 반환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySNaXYOHMffQ"
      },
      "source": [
        "### 오차함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SX7hj2JceMs"
      },
      "source": [
        "# 회귀함수의 경우\n",
        "loss = nn.MSELoss()\n",
        "input = Variable(torch.randn(3,5), requires_grad = True)\n",
        "target = Variable(torch.randan(3,5))\n",
        "output = loss(input, target)\n",
        "output.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JamU2RuKP7Yh"
      },
      "source": [
        "# 분류를 위한 엔트로피 구현 - torch ver\n",
        "loss = nn.CrossEntropyLoss()\n",
        "input = Variable(torch.randn(3, 5), requires_grad = True)\n",
        "target = variable(torch.LongTensor(3).random_(5))\n",
        "output = loss(input, target)\n",
        "output.backward()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddKoeWVzqcm-"
      },
      "source": [
        "# 교차 엔트로피 구현\n",
        "def cross_entropy(true_label, prediction):\n",
        "  if true_label == 1:\n",
        "    return -log(prediction)\n",
        "  else:\n",
        "    return -log(1 - prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSL3D_HTrm0q"
      },
      "source": [
        "### 가중치의 최적화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9CTncrBrrx5"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "for input, target in dataset:\n",
        "  optimizer.zero_grad()\n",
        "  output = model(input)\n",
        "  loss = loss_fn(output, target)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx0o_LSMr0Va"
      },
      "source": [
        "## 딥러닝을 이용한 이미지 분류\n",
        "다음과 같은 단계로 이미지 분류를 실시한다.\n",
        "1. 데이터 분류 실시\n",
        "2. 학습과 검증 데이터 셋의 분류\n",
        "3. Tensor로 데이터 로딩\n",
        "  - 이미지 같은 크기로 저장\n",
        "  - 데이터셋 정규화\n",
        "  - 이미지 데이터셋을 Pytorch Tensor로 변환\n",
        "4. 배치처리 형태로 Pytorch Tensor로 로딩\n",
        "5. 네트워크 아키텍처 구축\n",
        "6. 모델 학습\n",
        "\n",
        "세부적인 내용은 앞으로 배울 내용이므로, 각 부분별로 어떻게 구성되어있는지 개요만 부분적으로 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL_OJ3LDtyeD"
      },
      "source": [
        "# 데이터 분류 실시"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOfphhrat0mZ"
      },
      "source": [
        "# 학습과 검증 데이터 셋 분류"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-7moz0IuF9x"
      },
      "source": [
        "# Tensor로 데이터 로딩\n",
        "simple_transform = transforms.Compose([transforms.Scle((224,224)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(\n",
        "                                           [0.485, 0.456, 0.406],\n",
        "                                           [0.229, 0.224, 0.225]\n",
        "                                       )])\n",
        "train = ImageFolder('dogsandcats/train/',simple_transform)\n",
        "valid = ImageFolder('dogsandcats/valid/',simple_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnKsMqExvdrx"
      },
      "source": [
        "여기서 train_class는\n",
        "- train.class_to_idx - cat 0, dog 1\n",
        "- train.classes - [cat, dog]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2WLPTuOvJBx"
      },
      "source": [
        "# 배치처리 형태로 Tensor 로딩\n",
        "train_data_gen = torch.utils.data.DataLoder(train,batch_size = 64, num_workers = 3)\n",
        "valid_data_gen = torch.utils.data.DataLoder(valid,batch_size = 64, num_workers = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdMf8luAw2TP"
      },
      "source": [
        "네트워크 아키텍처는 컴퓨터 비전의 경우는 ImageNet, ResNet을 사용할 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftZe-DgRxHtZ"
      },
      "source": [
        "model_ft = models.resnet18(pretained = True)  # 인스턴스 출력\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "if is_cuda:\n",
        "  model_ft = model_ft.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmondHshyq93"
      },
      "source": [
        "# 모델의 학습 - 오차함수와 옵티마이저\n",
        "# 엔트로피로 오차함수, SDG를 기반으로 옵티마이저.\n",
        "# StepLR은 학습률의 조정.\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum = 0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size = 7, gamma = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnUXxPQB1MjX"
      },
      "source": [
        "# 최종_train_model\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs = 25):\n",
        "  since = time.time()\n",
        "\n",
        "  best_model_wts = model.state_dict()\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # 각 에폭의 구성 : 학습, 검증\n",
        "    for phase in ['train', 'valid']:\n",
        "      if phase == 'train':\n",
        "        scheduler.step()\n",
        "        model.train(True)\n",
        "        model.train(False)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for data in dataloaders[phase]:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UJiF0WeFIto",
        "outputId": "7f25577d-78b8-4913-8d04-20710e7cbe73"
      },
      "source": [
        "even_sum = 0\n",
        "for i in range(100):\n",
        "  if i % 2 == 0:\n",
        "    even_sum += i\n",
        "print(even_sum)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2450\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}