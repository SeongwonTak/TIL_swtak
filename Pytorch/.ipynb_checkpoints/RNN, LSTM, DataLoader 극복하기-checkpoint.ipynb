{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebf8f10",
   "metadata": {},
   "source": [
    "# RNN, LSTM, DataLoader 극복하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53f05d",
   "metadata": {},
   "source": [
    "몇 달째, 이들의 구현에서 정확하게 되고 있지 않아 지속적으로 고민하고 있다.\n",
    "이 참에 멸망전을 실시하여, 이 벽을 제대로 한번, 넘어가고자 한다.\n",
    "기존의 나의 코드와 비교하여 무엇이 문제인지, 어떤 부분을 극복해야 하는지를 확인하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701f126",
   "metadata": {},
   "source": [
    "## 극복 1. DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608a52b",
   "metadata": {},
   "source": [
    "데이터를 1개, 1개 학습을 시키는 방법도 가능하지만 Pytorch를 활용하면 Mini-Batch 단위의 학습이 가능하다. 또한 데이터를 무작위로 섞어줄 수 있다는 장점이 있다. 또한, 데이터셋을 불러오고 관리하는 과정을 간결하게 표현 가능하기에  DataLoader의 활용은 중요할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36086bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d4b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49be551c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 9\n"
     ]
    }
   ],
   "source": [
    "# 이미지와 정답(label)을 표시합니다.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[63].squeeze()\n",
    "label = train_labels[63]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb4bee",
   "metadata": {},
   "source": [
    "## 극복2. RNN & LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9af9f4",
   "metadata": {},
   "source": [
    "이상하게, 그동안 언어 전처리를 하면 RNN/LSTM 분류 문제에서 원하는 값을 잘 주지 못하는 것 같다.  \n",
    "다른 실습 코드를 바탕으로 RNN & LSTM를 활용한 classification 문제를 해결해보려고 한다.  \n",
    "이를 바탕으로 그동안 어느 부분을 잘못 알고 있었는지를 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c0639",
   "metadata": {},
   "source": [
    "### RNN 실습\n",
    "RNN의 경우는 다음과 같은 코드를 바탕으로 실습했다.\n",
    "https://wikidocs.net/60691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd480d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets, legacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213cb0b4",
   "metadata": {},
   "source": [
    "고정해야 하는 값들을 고정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80ea32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 5\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62232a",
   "metadata": {},
   "source": [
    "CPU로 설정해서 진행하자.\n",
    "또한 torch_text.legacy로 진행을 해야, 데이터가 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a21f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = legacy.data.Field(sequential=True, batch_first=True, lower=True)\n",
    "LABEL = legacy.data.Field(sequential=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1121ed",
   "metadata": {},
   "source": [
    "atch_first는 신경망에 입력되는 텐서의 첫번째 차원값이 batch_size가 되도록 합니다.   \n",
    "그리고 lower 변수를 통해 텍스트 데이터 속 모든 영문 알파벳이 소문자가 되도록 합니다.  \n",
    "소문자 처리를 하지 않을 경우 Apple과 apple을 동일하게 여길 수 없습니다. 따라서 소문자 통일화는 필수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca92baa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전체 데이터를 훈련 데이터와 테스트 데이터를 8:2 비율로 나누기\n",
    "trainset, testset = legacy.datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c49a70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합의 생성\n",
    "# min_freq를 통해서 5번도 안나온 단어는 <unk>가 될 것이다.\n",
    "TEXT.build_vocab(trainset, min_freq=5) # 단어 집합 생성\n",
    "LABEL.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "191f1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = trainset.split(split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6632b51f",
   "metadata": {},
   "source": [
    "토치텍스트는 모든 텍스트를 배치 처리하는 것을 지원하고, \n",
    "단어를 인덱스 번호로 대체하는 BucketIterator를 제공합니다. \n",
    "BucketIterator는 batch_size, device, shuffle 등의 인자를 받습니다. BATCH_SIZE는 앞서 64로 설정했었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd43151",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = legacy.data.BucketIterator.splits(\n",
    "        (trainset, valset, testset), batch_size=BATCH_SIZE,\n",
    "        shuffle=True, repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75844548",
   "metadata": {},
   "source": [
    "이 과정을 통해서, sample과 label이 64개씩 묶여서 미니배치를 이루게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3881fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
    "                          num_layers=self.n_layers,\n",
    "                          batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        h_0 = self._init_state(batch_size=x.size(0)) # 첫번째 히든 스테이트를 0벡터로 초기화\n",
    "        x, _ = self.gru(x, h_0)  # GRU의 리턴값은 (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\n",
    "        h_t = x[:,-1,:] # (배치 크기, 은닉 상태의 크기)의 텐서로 크기가 변경됨. 즉, 마지막 time-step의 은닉 상태만 가져온다.\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)  # (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\n",
    "        return logit\n",
    "\n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e421f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7e5e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(1, 256, vocab_size, 128, n_classes, 0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "922ecc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        x, y = batch.text, batch.label\n",
    "        y.data.sub_(1)  # 레이블 값을 0과 1로 변환\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16a30b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    \"\"\"evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text, batch.label\n",
    "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "158c7f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] val loss :  0.70 | val accuracy : 50.56\n",
      "[Epoch: 2] val loss :  0.67 | val accuracy : 58.38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-8c93332d8fae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_val_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-1dd819eb9a60>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, train_iter)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in range(1, EPOCHS+1):\n",
    "    train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "    print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (e, val_loss, val_accuracy))\n",
    "\n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969f709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
