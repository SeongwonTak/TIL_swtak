{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroDLwithPytorch03_02.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPoMBc30Y1Z+0DElG1VI4XJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongwonTak/TIL_swtak/blob/master/DLBasic/IntroDLwithPytorch03_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLGeFdOd0jAh"
      },
      "source": [
        "## Mini Batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed6Vk1D88nID"
      },
      "source": [
        "Mini Batch 학습법은 데이터가 매우 많을 때, 유용한 방법이다. 전체 데이터를 더 작은 단위로 나누어서 해당 단위로 학습하는 개념이다.\n",
        "\n",
        "전체 단위를 미니 배치 단위로 나눈다.\n",
        "데이터를 미니배치만큼 가져가서 비용을 계산한 후에 경사 하강법을 수행한다. \n",
        "다음 미니배치를 가져가서 경사 하강법을 수행 후 마지막 미니배치까지 반복을 한다. 이렇게 전체 데이터에 대한 학습이 1회 끝나면 **1에포크가** 끝났다고 한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yGvCceT-knS"
      },
      "source": [
        "### 이터레이션\n",
        "에포크와 배치 크기, 이터레이션의 관계\n",
        "이터레이션 * 배치 사이즈 = 토탈 데이터로, 토탈 데이터를 한번 돌면 1에포크가 된다.\n",
        "\n",
        "미니 배치는 통상적으로 2의 거듭제곱꼴을 쓴다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5OEmUT48jSS"
      },
      "source": [
        "# 도구 로드\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzYGaiXy0f1H"
      },
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  90], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRGAHy9o_5Wg"
      },
      "source": [
        "dataset = TensorDataset(x_train, y_train)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9KbTBOpAByF"
      },
      "source": [
        "# 모델 중심\n",
        "model = nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4zDfxowAFCS",
        "outputId": "ae7c23f8-f099-463f-8e45-cdff204904c1"
      },
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    print(batch_idx)\n",
        "    print(samples)\n",
        "    x_train, y_train = samples\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    0/20 Batch 1/1 Cost: 21127.750000\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    1/20 Batch 1/1 Cost: 9006.302734\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    2/20 Batch 1/1 Cost: 3839.192871\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    3/20 Batch 1/1 Cost: 1636.564575\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    4/20 Batch 1/1 Cost: 697.632141\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    5/20 Batch 1/1 Cost: 297.385651\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    6/20 Batch 1/1 Cost: 126.768921\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    7/20 Batch 1/1 Cost: 54.038963\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    8/20 Batch 1/1 Cost: 23.035635\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch    9/20 Batch 1/1 Cost: 9.819677\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   10/20 Batch 1/1 Cost: 4.185825\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   11/20 Batch 1/1 Cost: 1.784362\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   12/20 Batch 1/1 Cost: 0.760613\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   13/20 Batch 1/1 Cost: 0.324248\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   14/20 Batch 1/1 Cost: 0.138209\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   15/20 Batch 1/1 Cost: 0.058921\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   16/20 Batch 1/1 Cost: 0.025115\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   17/20 Batch 1/1 Cost: 0.010706\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   18/20 Batch 1/1 Cost: 0.004565\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   19/20 Batch 1/1 Cost: 0.001946\n",
            "0\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch   20/20 Batch 1/1 Cost: 0.000829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0JRLh7mAbsc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}