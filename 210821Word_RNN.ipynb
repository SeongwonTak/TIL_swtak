{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210821Word_RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNsQOiSo+iyeoXFLxBF4QOi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongwonTak/TIL_swtak/blob/master/210821Word_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjcPPfg5Vrg0"
      },
      "source": [
        "# Word 단위 RNN\n",
        "https://wikidocs.net/64765  로 다른 문장으로 직접 따라 실습한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRowY57iVyY0"
      },
      "source": [
        "# 훈련 데이터의 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HabttEvJEyVx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr3OS21kV9wp",
        "outputId": "c06c17d3-5109-45d1-cb74-ea9a996d3447"
      },
      "source": [
        "sentence = 'the quick brown fox jumps over the lazy dog'.split()\n",
        "vocab = list(set(sentence))\n",
        "print(vocab)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'quick', 'fox', 'jumps', 'dog', 'brown', 'lazy', 'over']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj_q5S56WO4X"
      },
      "source": [
        "vocab을 단어장으로 활용할려고 한다.\n",
        "이제 단어장의 단어 들에 고유한 정수 인덱스를 부여한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvqdDC0HWJey",
        "outputId": "e50ca3a8-884f-49d8-b64d-9393c5490311"
      },
      "source": [
        "word2index = {tkn : i for i, tkn in enumerate(vocab, 1)}\n",
        "# 단어장에 없는 단어를 의미하는 토큰을 추가한다.\n",
        "word2index['<unk>'] = 0\n",
        "print(word2index)\n",
        "\n",
        "# 인덱스를 다시 단어로 바꿔주는 딕셔너리도 만들어준다.\n",
        "index2word = {v: k for k, v in word2index.items()}\n",
        "print(index2word)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'quick': 2, 'fox': 3, 'jumps': 4, 'dog': 5, 'brown': 6, 'lazy': 7, 'over': 8, '<unk>': 0}\n",
            "{1: 'the', 2: 'quick', 3: 'fox', 4: 'jumps', 5: 'dog', 6: 'brown', 7: 'lazy', 8: 'over', 0: '<unk>'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CFOTUzGWl4j"
      },
      "source": [
        "# 훈련 데이터 설계\n",
        "# 마지막 단어를 제외하고 문장을 비우고, 문장을 완성하는 문제를 풀 것이다.\n",
        "\n",
        "def build_data(sentence, word2index):\n",
        "    encoded = [word2index[token] for token in sentence] # 각 문자를 정수로 변환. \n",
        "    input_seq, label_seq = encoded[:-1], encoded[1:] # 입력 시퀀스와 레이블 시퀀스를 분리\n",
        "    input_seq = torch.LongTensor(input_seq).unsqueeze(0) # 배치 차원 추가\n",
        "    label_seq = torch.LongTensor(label_seq).unsqueeze(0) # 배치 차원 추가\n",
        "    return input_seq, label_seq"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI90EjSaWu4H"
      },
      "source": [
        "X, Y = build_data(sentence, word2index)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZelRLS9wYUKK"
      },
      "source": [
        "## 모델의 구현\n",
        "RNN을 활용하여 모델을 만들고자 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPV_J5WqYPJj"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, vocab_size, input_size, hidden_size, batch_first = True):\n",
        "    super(Net, self).__init__()\n",
        "    self.embedding_layer = nn.Embedding(num_embeddings= vocab_size,\n",
        "                                        embedding_dim = input_size)\n",
        "    self.rnn_layer = nn.RNN(input_size, hidden_size, batch_first=batch_first)\n",
        "    self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.embedding_layer(x)\n",
        "    output, hidden = self.rnn_layer(output)\n",
        "    output = self.linear(output)\n",
        "\n",
        "    return output.view(-1, output.size(2))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhPEnYXkZEyM"
      },
      "source": [
        "# hyperparameter\n",
        "vocab_size = len(word2index)  # 단어장의 크기는 임베딩 층, 최종 출력층에 사용된다. <unk> 토큰을 크기에 포함한다.\n",
        "input_size = 5  # 임베딩 된 차원의 크기 및 RNN 층 입력 차원의 크기\n",
        "hidden_size = 20  # RNN의 은닉층 크기"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbix1UTnZJkn",
        "outputId": "75acd41b-99a2-4f4e-bd5d-466691c289d8"
      },
      "source": [
        "# 모델 생성\n",
        "model = Net(vocab_size, input_size, hidden_size, batch_first=True)\n",
        "# 손실함수 정의\n",
        "loss_function = nn.CrossEntropyLoss() # 소프트맥스 함수 포함이며 실제값은 원-핫 인코딩 안 해도 됨.\n",
        "# 옵티마이저 정의\n",
        "optimizer = optim.Adam(params=model.parameters())\n",
        "\n",
        "output = model(X)\n",
        "print(output)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0524,  0.1287,  0.1051, -0.0219,  0.2135,  0.0424, -0.0127, -0.2107,\n",
            "          0.1589],\n",
            "        [-0.1561, -0.3218,  0.0215,  0.0784,  0.1254,  0.1570,  0.0123, -0.0559,\n",
            "          0.1838],\n",
            "        [-0.2528,  0.3364,  0.2524, -0.1313,  0.2534, -0.2731, -0.0207, -0.3205,\n",
            "          0.1208],\n",
            "        [-0.1287, -0.2458,  0.0111,  0.0878,  0.2104, -0.0155,  0.0402, -0.1065,\n",
            "          0.1548],\n",
            "        [-0.0290,  0.3623,  0.2548,  0.1784,  0.5064, -0.2112, -0.2846, -0.1630,\n",
            "         -0.2226],\n",
            "        [-0.0101, -0.1975,  0.1773,  0.0819,  0.1948,  0.0265,  0.1447, -0.0145,\n",
            "          0.0460],\n",
            "        [-0.0361,  0.1567,  0.1094,  0.0575,  0.3404, -0.1210, -0.1082, -0.2475,\n",
            "          0.2264],\n",
            "        [-0.1662, -0.0385,  0.1395, -0.1015,  0.0748, -0.0856, -0.1084, -0.0587,\n",
            "          0.0455]], grad_fn=<ViewBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZfy16mhZOhJ"
      },
      "source": [
        "# 수치화된 데이터를 단어로 전환하는 함수\n",
        "decode = lambda y: [index2word.get(x) for x in y]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrYGo1ZRZXqJ",
        "outputId": "8b4a4638-bb0d-4e23-9e72-b512899c0cf9"
      },
      "source": [
        "# 훈련 시작\n",
        "for step in range(201):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(X)\n",
        "    loss = loss_function(output, Y.view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 기록\n",
        "    if step % 40 == 0:\n",
        "        print(\"[{:02d}/201] {:.4f} \".format(step+1, loss))\n",
        "        pred = output.softmax(-1).argmax(-1).tolist()\n",
        "        print(\" \".join([\"Repeat\"] + decode(pred)))\n",
        "        print()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[01/201] 2.2998 \n",
            "Repeat jumps over the jumps jumps jumps jumps quick\n",
            "\n",
            "[41/201] 1.8815 \n",
            "Repeat quick brown fox jumps jumps brown fox dog\n",
            "\n",
            "[81/201] 1.2948 \n",
            "Repeat quick brown fox jumps over the lazy dog\n",
            "\n",
            "[121/201] 0.7270 \n",
            "Repeat quick brown fox jumps over the lazy dog\n",
            "\n",
            "[161/201] 0.3990 \n",
            "Repeat quick brown fox jumps over the lazy dog\n",
            "\n",
            "[201/201] 0.2309 \n",
            "Repeat quick brown fox jumps over the lazy dog\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpPRjqu5ZfkL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}